[{"authors":["Ao Zhou"],"categories":null,"content":"Ao Zhou is a Ph.D. Student in Beihang University of Computer Science. His research focuses around the acceleration of graph neural networks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"805bd03e39ccfb3bef42b673e83cb009","permalink":"http://localhost:1313/author/ao-zhou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ao-zhou/","section":"authors","summary":"Ao Zhou is a Ph.D. Student in Beihang University of Computer Science. His research focuses around the acceleration of graph neural networks.","tags":null,"title":"Ao Zhou","type":"authors"},{"authors":null,"categories":null,"content":"Associate Professor Institute of Advanced Computing Technology (ACT) School of Computer Science and Engineering\nSpintronics Interdisciplinary Research Center, Fert Beijing Research Institute\\\nPostdoc in the EI Lab at University of Pittsburgh (2016) Ph.D. in CS at Tsinghua University (2014)\nEmail: jianlei@buaa.edu.cn\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"21f1d8279a26ff37885afbd400151a24","permalink":"http://localhost:1313/author/jianlei-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jianlei-yang/","section":"authors","summary":"Associate Professor Institute of Advanced Computing Technology (ACT) School of Computer Science and Engineering\nSpintronics Interdisciplinary Research Center, Fert Beijing Research Institute\\\nPostdoc in the EI Lab at University of Pittsburgh (2016) Ph.","tags":null,"title":"Jianlei Yang","type":"authors"},{"authors":null,"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://localhost:1313/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"http://localhost:1313/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cc1d577ace897b3249806667f4155d1c","permalink":"http://localhost:1313/resources/dnn-training-accelerator-comparison/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resources/dnn-training-accelerator-comparison/","section":"resources","summary":"Deep Graph Learning Systems","tags":null,"title":"dnn-training-accelerator-comparison","type":"resources"},{"authors":null,"categories":null,"content":"Relevant publications S2Engine: A Novel Systolic Architecture for Sparse Convolutional Neural Networks Jianlei Yang, Wenzhi Fu, Xingzhou Cheng, Xucheng Ye, Pengcheng Dai, Weisheng Zhao. accepted by IEEE Transactions on Computers (TC), 2021. Accelerating CNN Training by Pruning Activation Gradients Xucheng Ye, Pengcheng Dai, Junyu Luo, Xin Guo, Yingjie Qi, Jianlei Yang, Yiran Chen. ECCV 2020 SparseTrain: Exploiting Dataflow Sparsity for Efficient Convolutional Neural Networks Training Pengcheng Dai, Jianlei Yang, Xucheng Ye, Xingzhou Cheng, Junyu Luo, Linghao Song, Yiran Chen and Weisheng Zhao. DAC 2020 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"dc7f0fad6e755992d0124f59dde23d0d","permalink":"http://localhost:1313/research/efficient-deep-learning-system/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/efficient-deep-learning-system/","section":"research","summary":"Efficient Deep Learning Systems","tags":null,"title":"Efficient Deep Learning Systems","type":"research"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbe31627ef2951e69d002fb6b46b213e","permalink":"http://localhost:1313/research/deep-graph-learning-systems/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/deep-graph-learning-systems/","section":"research","summary":"Deep Graph Learning Systems","tags":null,"title":"Deep Graph Learning Systems","type":"research"},{"authors":null,"categories":null,"content":"Relevant publications S2Engine: A Novel Systolic Architecture for Sparse Convolutional Neural Networks Jianlei Yang, Wenzhi Fu, Xingzhou Cheng, Xucheng Ye, Pengcheng Dai, Weisheng Zhao. accepted by IEEE Transactions on Computers (TC), 2021. Accelerating CNN Training by Pruning Activation Gradients Xucheng Ye, Pengcheng Dai, Junyu Luo, Xin Guo, Yingjie Qi, Jianlei Yang, Yiran Chen. ECCV 2020 SparseTrain: Exploiting Dataflow Sparsity for Efficient Convolutional Neural Networks Training Pengcheng Dai, Jianlei Yang, Xucheng Ye, Xingzhou Cheng, Junyu Luo, Linghao Song, Yiran Chen and Weisheng Zhao. DAC 2020 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"762792f25d0028519238857e6a65c4a7","permalink":"http://localhost:1313/resources/literature-on-graph-neural-networks-acceleratio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resources/literature-on-graph-neural-networks-acceleratio/","section":"resources","summary":"literature-on-graph-neural-networks-acceleratio","tags":null,"title":"literature-on-graph-neural-networks-acceleratio","type":"resources"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://localhost:1313/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Ao Zhou","Jianlei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Contribution to PyG.\n","date":1616198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616198400,"objectID":"37c46aaabd6be3a7e01cb6cd10cbd502","permalink":"http://localhost:1313/publication/rtas2021/","publishdate":"2021-03-20T00:00:00Z","relpermalink":"/publication/rtas2021/","section":"publication","summary":"Graph neural networks (GNN) have achieved stateof-the-art performance on various industrial tasks. However, the poor efficiency of GNN inference and frequent Out-OfMemory (OOM) problem limit the successful application of GNN on edge computing platforms. To tackle these problems, a feature decomposition approach is proposed for memory efficiency optimization of GNN inference. The proposed approach could achieve outstanding optimization on various GNN models, covering a wide range of datasets, which speeds up the inference by up to 3×. Furthermore, the proposed feature decomposition could significantly reduce the peak memory usage (up to 5× in memory efficiency improvement) and mitigate OOM problems during GNN inference.","tags":["Source Themes"],"title":"optimizing Memory Efficiency of Graph Neural Networks on Edge Computing Platforms","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"http://localhost:1313/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"http://localhost:1313/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"Paper title: Eventor: An Efficient Event-Based Monocular Multi-View Stereo Accelerator on FPGA Platform.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"554534296938c1ad3a92340169ecb3d0","permalink":"http://localhost:1313/post/22-2-01-dac/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/22-2-01-dac/","section":"post","summary":"Paper title: Eventor: An Efficient Event-Based Monocular Multi-View Stereo Accelerator on FPGA Platform.\n","tags":null,"title":"One research paper is accepted by ACM/IEEE DAC 2022!","type":"post"},{"authors":null,"categories":null,"content":"Paper title: Accelerating Graph Connected Component Computation with Emerging Processing-In-Memory Architecture.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2174fd0f33959273c90d29aa45ea7ddc","permalink":"http://localhost:1313/post/22-3-01-tcad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/22-3-01-tcad/","section":"post","summary":"Paper title: Accelerating Graph Connected Component Computation with Emerging Processing-In-Memory Architecture.","tags":null,"title":"One research paper is accepted by IEEE TCAD!","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"http://localhost:1313/tour/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"widget_page"}]